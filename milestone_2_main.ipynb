{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main.py\n",
    "It serves as the entry point of the project Milestone 2 and contains the code to initialize and coordinate\n",
    "the execution of other modules or classes.\n",
    "\n",
    "It call methods that\n",
    "    Connect to source and download data\n",
    "    Clean the data\n",
    "    Upload the data to a Postgresql database on localhost named sales_data\n",
    "\n",
    "Those methods are contained in three classes coded in the files\n",
    "\n",
    "- DatabaseConnector ---> database_utils.py\n",
    "- DataCleaning --> data_cleaning.py\n",
    "- DataExtractor --> data_extraction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the DatabaseConnector class for connecting and uploading data from various sources\n",
    "from database_utils import DatabaseConnector as database_connector\n",
    "# import the data cleaning Class\n",
    "from data_cleaning import DataCleaning as data_cleaner\n",
    "# import the DataExtractor class\n",
    "from data_extraction import DataExtractor as data_extractor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the connection credential for the SQL databased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HOST': 'localhost', 'USER': 'postgres', 'PASSWORD': 'macchio', 'DATABASE': 'sales_data_test01', 'PORT': 5432}\n"
     ]
    }
   ],
   "source": [
    "# file_name_psql should contain the yaml file with the credentials\n",
    "file_name_psql = 'postgresql_creds.yaml'\n",
    "cred_dict_psql = database_connector.read_db_creds(file_name_psql)\n",
    "print(cred_dict_psql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL engine successfully connected\n",
      "['legacy_store_details', 'legacy_users', 'orders_table']\n",
      "{'HOST': 'localhost', 'USER': 'postgres', 'PASSWORD': 'macchio', 'DATABASE': 'sales_data_test01', 'PORT': 5432}\n"
     ]
    }
   ],
   "source": [
    "# the credata_extractorntials to connect the RDS AWS server are stored in this yaml file\n",
    "file_name = 'db_creds.yaml'\n",
    "\n",
    "# read credata_extractorntial and transform them from yaml to dict\n",
    "cred_dict = database_connector.read_db_creds(file_name)\n",
    "\n",
    "# initialize the SQLalchemy engine\n",
    "RDS_engine = database_connector.init_db_engine(cred_dict)\n",
    "\n",
    "# get the list of tables in the RDS database\n",
    "tables_list = data_extractor.list_db_tables(RDS_engine)\n",
    "\n",
    "# print the list of tables\n",
    "print(tables_list)\n",
    "\n",
    "# read the data from the RDS table of users and stores in the users_data variable\n",
    "users_data = data_extractor.read_RDS_table(tables_list[1], RDS_engine)\n",
    "\n",
    "\n",
    "# clean the user data via the relative method\n",
    "user_data_clean = data_cleaner.clean_user_data(users_data)\n",
    "\n",
    "# upload the user data to the SQL server\n",
    "database_connector.upload_to_db(user_data_clean, 'dim_users', cred_dict_psql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Card data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the card data\n",
    "pdf_link = 'https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf'\n",
    "card_data = data_extractor.retrieve_pdf_data(pdf_link)\n",
    "\n",
    "# clean the data through the relative method\n",
    "card_data_clean = data_cleaner.clean_card_data(card_data)\n",
    "\n",
    "# upload the card data to the SQL server\n",
    "database_connector.upload_to_db(card_data_clean, 'dim_card_details', cred_dict_psql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stores data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of stores to be extracted is:  451\n",
     ]
    }
   ],
   "source": [
    "# key and url to access the number of stores \n",
    "key = {'x-api-key': 'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "url = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores'\n",
    "\n",
    "# retrieve the number of stores\n",
    "number_of_stores = data_extractor.list_number_of_stores(url, key)\n",
    "\n",
    "# print the number of stores\n",
    "print(\"the number of stores to be extracted is: \", number_of_stores)\n",
    "\n",
    "# url for the stores information\n",
    "base_url = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/'\n",
    "\n",
    "# download the information for each store\n",
    "stores_df = data_extractor.retrieve_stores_data(base_url, number_of_stores, key)\n",
    "\n",
    "# clean the stores data\n",
    "stores_data_clean = data_cleaner.clean_store_data(stores_df)\n",
    "\n",
    "# upload the stores data to the SQL database\n",
    "database_connector.upload_to_db(stores_data_clean, 'dim_store_details', cred_dict_psql)\n",
    "print('upload successful')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log into AWS CLI with (i) Access Key ID and (ii) Secret Access Key\n",
    "import subprocess\n",
    "\n",
    "# Pause script execution\n",
    "input(\"Press Enter to pause the script and log in to AWC CLI\")\n",
    "\n",
    "# Log into AWS CLI\n",
    "subprocess.call([\"aws\", \"configure\"])\n",
    "\n",
    "# extract the products data from the s3 server\n",
    "products_df = data_extractor.extract_from_s3('s3://data-handling-public/', filename = 'products.csv')\n",
    "\n",
    "# clean the data\n",
    "products_df_clean = data_cleaner.clean_product_data(products_df)\n",
    "products_df_clean_converted_units = data_cleaner.clean_product_weights(products_df_clean)\n",
    "\n",
    "# upload to the SQL server\n",
    "database_connector.upload_to_db(products_df_clean_converted_units, 'dim_products', cred_dict_psql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orders data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_details_downloaded\n",
      "cleaning date details\n"
     ]
    }
   ],
   "source": [
    "orders_data = data_extractor.read_RDS_table(tables_list[2], RDS_engine)\n",
    "orders_data_clean = data_cleaner.clean_orders_data(orders_data)\n",
    "\n",
    "database_connector.upload_to_db(orders_data_clean, 'orders_table', cred_dict_psql)\n",
    "\n",
    "url = 'https://data-handling-public.s3.eu-west-1.amazonaws.com/date_details.json'\n",
    "date_details = data_extractor.download_date_details(url)\n",
    "print('date_details_downloaded')\n",
    "date_details_clean = data_cleaner.clean_date_details(date_details)\n",
    "\n",
    "database_connector.upload_to_db(date_details_clean, 'dim_date_times', cred_dict_psql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
